{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "SECRETS_PATH = Path(\"../.secrets/kaggle.json\")\n",
        "if SECRETS_PATH.exists():\n",
        "    with open(SECRETS_PATH) as f:\n",
        "        creds = json.load(f)\n",
        "    os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
        "    os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]\n",
        "else:\n",
        "    raise FileNotFoundError(\"Missing Kaggle credentials at ../.secrets/kaggle.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, Iterable, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import clone\n",
        "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import (\n",
        "    BaggingRegressor,\n",
        "    ExtraTreesRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    RandomForestRegressor,\n",
        "    StackingRegressor,\n",
        "    VotingRegressor,\n",
        ")\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, StandardScaler\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "pd.set_option(\"display.width\", 160)\n",
        "RANDOM_STATE = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"../data\")\n",
        "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
        "TEST_PATH = DATA_DIR / \"test.csv\"\n",
        "SUBMISSIONS_DIR = DATA_DIR\n",
        "\n",
        "if not TRAIN_PATH.exists():\n",
        "    raise FileNotFoundError(\"Expected train.csv under ../data\")\n",
        "if not TEST_PATH.exists():\n",
        "    raise FileNotFoundError(\"Expected test.csv under ../data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1460, 80), (1459, 79))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(TRAIN_PATH).set_index(\"Id\")\n",
        "test_df = pd.read_csv(TEST_PATH).set_index(\"Id\")\n",
        "\n",
        "y = train_df[\"SalePrice\"]\n",
        "X = train_df.drop(columns=\"SalePrice\")\n",
        "\n",
        "train_df.shape, test_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_engineered_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Add domain-driven aggregates, ratios, and indicator features.\"\"\"\n",
        "\n",
        "    result = df.copy()\n",
        "    safe_div = lambda num, den: num / (den + 1e-6)\n",
        "\n",
        "    result[\"TotalSF\"] = (\n",
        "        result.get(\"TotalBsmtSF\", 0)\n",
        "        + result.get(\"1stFlrSF\", 0)\n",
        "        + result.get(\"2ndFlrSF\", 0)\n",
        "    )\n",
        "    result[\"TotalBath\"] = (\n",
        "        result.get(\"FullBath\", 0)\n",
        "        + 0.5 * result.get(\"HalfBath\", 0)\n",
        "        + result.get(\"BsmtFullBath\", 0)\n",
        "        + 0.5 * result.get(\"BsmtHalfBath\", 0)\n",
        "    )\n",
        "    result[\"AgeAtSale\"] = result.get(\"YrSold\", 0) - result.get(\"YearBuilt\", 0)\n",
        "    result[\"SinceRemodel\"] = result.get(\"YrSold\", 0) - result.get(\"YearRemodAdd\", 0)\n",
        "    result[\"IsRemodeled\"] = (result.get(\"YearBuilt\", 0) != result.get(\"YearRemodAdd\", 0)).astype(int)\n",
        "    result[\"TotalPorchSF\"] = (\n",
        "        result.get(\"OpenPorchSF\", 0)\n",
        "        + result.get(\"EnclosedPorch\", 0)\n",
        "        + result.get(\"3SsnPorch\", 0)\n",
        "        + result.get(\"ScreenPorch\", 0)\n",
        "        + result.get(\"WoodDeckSF\", 0)\n",
        "    )\n",
        "    result[\"HasPool\"] = (result.get(\"PoolArea\", 0) > 0).astype(int)\n",
        "    result[\"HasGarage\"] = (result.get(\"GarageArea\", 0) > 0).astype(int)\n",
        "    result[\"HasFireplace\"] = (result.get(\"Fireplaces\", 0) > 0).astype(int)\n",
        "    result[\"LotRatio\"] = safe_div(result.get(\"GrLivArea\", 0), result.get(\"LotArea\", 1))\n",
        "    result[\"LogLotArea\"] = np.log1p(result.get(\"LotArea\", 0))\n",
        "    result[\"LogGrLivArea\"] = np.log1p(result.get(\"GrLivArea\", 0))\n",
        "    result[\"QualityScore\"] = result.get(\"OverallQual\", 0) * result.get(\"OverallCond\", 0)\n",
        "    result[\"LivLotRatio\"] = safe_div(result.get(\"GrLivArea\", 0), result.get(\"LotArea\", 1))\n",
        "    result[\"BedBathRatio\"] = safe_div(\n",
        "        result.get(\"BedroomAbvGr\", 0),\n",
        "        result.get(\"FullBath\", 0) + 0.5 * result.get(\"HalfBath\", 0) + 1,\n",
        "    )\n",
        "    result[\"RoomsPerSF\"] = safe_div(result.get(\"TotRmsAbvGrd\", 0), result.get(\"GrLivArea\", 1))\n",
        "    result[\"GarageCarsToArea\"] = safe_div(result.get(\"GarageCars\", 0), result.get(\"GarageArea\", 1))\n",
        "    result[\"GarageAge\"] = result.get(\"YrSold\", 0) - result.get(\"GarageYrBlt\", result.get(\"YearBuilt\", 0))\n",
        "    result[\"OutdoorSF\"] = result.get(\"TotalPorchSF\", 0) + result.get(\"WoodDeckSF\", 0)\n",
        "    result[\"IsNew\"] = (result.get(\"YearBuilt\", 0) >= result.get(\"YrSold\", 0) - 1).astype(int)\n",
        "    result[\"RemodelAgeRatio\"] = safe_div(result.get(\"SinceRemodel\", 0), result.get(\"AgeAtSale\", 0) + 1)\n",
        "    result[\"BsmtFinRatio\"] = safe_div(result.get(\"BsmtFinSF1\", 0) + result.get(\"BsmtFinSF2\", 0), result.get(\"TotalBsmtSF\", 0) + 1)\n",
        "    result[\"TotalFunctionalSF\"] = result.get(\"TotalSF\", 0) + result.get(\"TotalPorchSF\", 0)\n",
        "    result[\"LogTotalSF\"] = np.log1p(result.get(\"TotalSF\", 0))\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1460, 103), (1459, 103))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_fe = add_engineered_features(X)\n",
        "test_fe = add_engineered_features(test_df)\n",
        "\n",
        "X_fe.shape, test_fe.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60, 43)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numeric_features = X_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = [col for col in X_fe.columns if col not in numeric_features]\n",
        "\n",
        "len(numeric_features), len(categorical_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RepeatedKFold(n_repeats=2, n_splits=5, random_state=42)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numeric_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"power\", PowerTransformer(method=\"yeo-johnson\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipeline, numeric_features),\n",
        "        (\"cat\", categorical_pipeline, categorical_features),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=RANDOM_STATE)\n",
        "cv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_pipeline(name: str, pipeline: Pipeline, X_data: pd.DataFrame, y_data: pd.Series, splitter: RepeatedKFold) -> Dict[str, float]:\n",
        "    fold_rows: List[Dict[str, float]] = []\n",
        "\n",
        "    for fold_idx, (train_idx, valid_idx) in enumerate(splitter.split(X_data, y_data), start=1):\n",
        "        X_train, X_valid = X_data.iloc[train_idx], X_data.iloc[valid_idx]\n",
        "        y_train, y_valid = y_data.iloc[train_idx], y_data.iloc[valid_idx]\n",
        "\n",
        "        model = clone(pipeline)\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_valid)\n",
        "        preds = np.clip(preds, 1, None)\n",
        "\n",
        "        rmse = float(np.sqrt(mean_squared_error(y_valid, preds)))\n",
        "        log_rmse = float(np.sqrt(mean_squared_error(np.log1p(y_valid), np.log1p(preds))))\n",
        "        r2 = float(r2_score(y_valid, preds))\n",
        "\n",
        "        fold_rows.append({\"rmse\": rmse, \"log_rmse\": log_rmse, \"r2\": r2})\n",
        "\n",
        "    fold_df = pd.DataFrame(fold_rows)\n",
        "    return {\n",
        "        \"model\": name,\n",
        "        \"rmse_mean\": fold_df[\"rmse\"].mean(),\n",
        "        \"rmse_std\": fold_df[\"rmse\"].std(ddof=0),\n",
        "        \"log_rmse_mean\": fold_df[\"log_rmse\"].mean(),\n",
        "        \"log_rmse_std\": fold_df[\"log_rmse\"].std(ddof=0),\n",
        "        \"r2_mean\": fold_df[\"r2\"].mean(),\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_pipelines(pipelines: Dict[str, Pipeline], X_data: pd.DataFrame, y_data: pd.Series, splitter: RepeatedKFold) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    total = len(pipelines)\n",
        "    for idx, (name, pipe) in enumerate(pipelines.items(), start=1):\n",
        "        print(f\"[{idx}/{total}] Evaluating {name}...\", flush=True)\n",
        "        rows.append(evaluate_pipeline(name, pipe, X_data, y_data, splitter))\n",
        "    results = pd.DataFrame(rows)\n",
        "    return results.sort_values([\"log_rmse_mean\", \"rmse_mean\"]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_hgb(**kwargs) -> HistGradientBoostingRegressor:\n",
        "    params = dict(\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        max_iter=700,\n",
        "        min_samples_leaf=14,\n",
        "        l2_regularization=0.1,\n",
        "        max_leaf_nodes=None,\n",
        "    )\n",
        "    params.update(kwargs)\n",
        "    return HistGradientBoostingRegressor(random_state=RANDOM_STATE, **params)\n",
        "\n",
        "\n",
        "def make_gbr(**kwargs) -> GradientBoostingRegressor:\n",
        "    params = dict(\n",
        "        n_estimators=2000,\n",
        "        learning_rate=0.04,\n",
        "        max_depth=3,\n",
        "        subsample=0.9,\n",
        "        min_samples_leaf=2,\n",
        "        max_features=None,\n",
        "    )\n",
        "    params.update(kwargs)\n",
        "    return GradientBoostingRegressor(random_state=RANDOM_STATE, **params)\n",
        "\n",
        "\n",
        "def make_rf(**kwargs) -> RandomForestRegressor:\n",
        "    params = dict(\n",
        "        n_estimators=1000,\n",
        "        max_depth=None,\n",
        "        max_features=\"sqrt\",\n",
        "        min_samples_leaf=1,\n",
        "        bootstrap=True,\n",
        "    )\n",
        "    params.update(kwargs)\n",
        "    return RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1, **params)\n",
        "\n",
        "\n",
        "def make_extratrees(**kwargs) -> ExtraTreesRegressor:\n",
        "    params = dict(\n",
        "        n_estimators=1200,\n",
        "        max_depth=None,\n",
        "        max_features=0.6,\n",
        "        min_samples_leaf=1,\n",
        "        bootstrap=False,\n",
        "    )\n",
        "    params.update(kwargs)\n",
        "    return ExtraTreesRegressor(random_state=RANDOM_STATE, n_jobs=-1, **params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_registry: Dict[str, Pipeline] = {\n",
        "    \"HGB_baseline\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", make_hgb()),\n",
        "        ]\n",
        "    ),\n",
        "    \"HGB_deeper\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", make_hgb(max_depth=6, max_iter=900, min_samples_leaf=12)),\n",
        "        ]\n",
        "    ),\n",
        "    \"HGB_shrinkage\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\n",
        "                \"model\",\n",
        "                make_hgb(learning_rate=0.03, max_iter=1200, min_samples_leaf=20, max_depth=4, l2_regularization=0.2),\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "    \"HGB_with_pca\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"dim_red\", PCA(n_components=150, svd_solver=\"randomized\", random_state=RANDOM_STATE)),\n",
        "            (\"model\", make_hgb(max_depth=5, max_iter=600, min_samples_leaf=18)),\n",
        "        ]\n",
        "    ),\n",
        "    \"GBR_depth3\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", make_gbr()),\n",
        "        ]\n",
        "    ),\n",
        "    \"GBR_depth4\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\n",
        "                \"model\",\n",
        "                make_gbr(n_estimators=1600, learning_rate=0.05, max_depth=4, min_samples_leaf=3, subsample=0.85),\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "    \"RF_unbounded\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", make_rf()),\n",
        "        ]\n",
        "    ),\n",
        "    \"RF_regularized\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\n",
        "                \"model\",\n",
        "                make_rf(n_estimators=800, max_depth=24, max_features=0.4, min_samples_leaf=2),\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "    \"ExtraTrees_wide\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", make_extratrees()),\n",
        "        ]\n",
        "    ),\n",
        "    \"KernelRidge_rbf\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\"model\", KernelRidge(alpha=0.4, kernel=\"rbf\", gamma=5e-4)),\n",
        "        ]\n",
        "    ),\n",
        "    \"Bagging_HGB\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\n",
        "                \"model\",\n",
        "                BaggingRegressor(\n",
        "                    estimator=make_hgb(max_depth=4, learning_rate=0.06, max_iter=800, min_samples_leaf=18),\n",
        "                    n_estimators=12,\n",
        "                    max_features=0.9,\n",
        "                    random_state=RANDOM_STATE,\n",
        "                    n_jobs=-1,\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "    \"LogTarget_HGB\": Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", preprocessor),\n",
        "            (\n",
        "                \"model\",\n",
        "                TransformedTargetRegressor(\n",
        "                    regressor=make_hgb(max_depth=5, learning_rate=0.045, max_iter=900, min_samples_leaf=18),\n",
        "                    func=np.log1p,\n",
        "                    inverse_func=np.expm1,\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "}\n",
        "\n",
        "stack_estimators = [\n",
        "    (\"hgb\", make_hgb(max_depth=5, learning_rate=0.045, max_iter=850, min_samples_leaf=16)),\n",
        "    (\"gbr\", make_gbr(n_estimators=1800, learning_rate=0.045)),\n",
        "    (\"rf\", make_rf(n_estimators=900, max_depth=30, max_features=0.5)),\n",
        "]\n",
        "stack_final = make_gbr(n_estimators=800, learning_rate=0.06, max_depth=2)\n",
        "model_registry[\"Stacking_Trees\"] = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\n",
        "            \"model\",\n",
        "            StackingRegressor(\n",
        "                estimators=stack_estimators,\n",
        "                final_estimator=stack_final,\n",
        "                n_jobs=-1,\n",
        "                passthrough=False,\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "voting_estimators = [\n",
        "    (\"hgb\", make_hgb(max_depth=5, learning_rate=0.05, max_iter=700, min_samples_leaf=14)),\n",
        "    (\"gbr\", make_gbr(n_estimators=1500, learning_rate=0.05)),\n",
        "    (\"extratrees\", make_extratrees(n_estimators=1000, max_features=0.65)),\n",
        "]\n",
        "model_registry[\"Voting_TopTrees\"] = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\n",
        "            \"model\",\n",
        "            VotingRegressor(estimators=voting_estimators, weights=[0.4, 0.3, 0.3]),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "len(model_registry)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/14] Evaluating HGB_baseline...\n",
            "[2/14] Evaluating HGB_deeper...\n",
            "[3/14] Evaluating HGB_shrinkage...\n",
            "[4/14] Evaluating HGB_with_pca...\n",
            "[5/14] Evaluating GBR_depth3...\n",
            "[6/14] Evaluating GBR_depth4...\n",
            "[7/14] Evaluating RF_unbounded...\n",
            "[8/14] Evaluating RF_regularized...\n",
            "[9/14] Evaluating ExtraTrees_wide...\n",
            "[10/14] Evaluating KernelRidge_rbf...\n",
            "[11/14] Evaluating Bagging_HGB...\n",
            "[12/14] Evaluating LogTarget_HGB...\n",
            "[13/14] Evaluating Stacking_Trees...\n",
            "[14/14] Evaluating Voting_TopTrees...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>rmse_mean</th>\n",
              "      <th>rmse_std</th>\n",
              "      <th>log_rmse_mean</th>\n",
              "      <th>log_rmse_std</th>\n",
              "      <th>r2_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bagging_HGB</td>\n",
              "      <td>27399.551344</td>\n",
              "      <td>6357.185771</td>\n",
              "      <td>0.125295</td>\n",
              "      <td>0.015580</td>\n",
              "      <td>0.872584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Voting_TopTrees</td>\n",
              "      <td>26891.805115</td>\n",
              "      <td>7207.402720</td>\n",
              "      <td>0.125962</td>\n",
              "      <td>0.016404</td>\n",
              "      <td>0.873663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GBR_depth3</td>\n",
              "      <td>26850.105434</td>\n",
              "      <td>7685.488876</td>\n",
              "      <td>0.127057</td>\n",
              "      <td>0.015513</td>\n",
              "      <td>0.872124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GBR_depth4</td>\n",
              "      <td>26999.786581</td>\n",
              "      <td>6780.784243</td>\n",
              "      <td>0.128500</td>\n",
              "      <td>0.015043</td>\n",
              "      <td>0.873631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HGB_baseline</td>\n",
              "      <td>28193.519974</td>\n",
              "      <td>6890.107412</td>\n",
              "      <td>0.131251</td>\n",
              "      <td>0.017017</td>\n",
              "      <td>0.863069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LogTarget_HGB</td>\n",
              "      <td>27655.919103</td>\n",
              "      <td>5724.381698</td>\n",
              "      <td>0.131467</td>\n",
              "      <td>0.014711</td>\n",
              "      <td>0.871659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HGB_shrinkage</td>\n",
              "      <td>28360.440354</td>\n",
              "      <td>6010.141091</td>\n",
              "      <td>0.131557</td>\n",
              "      <td>0.013790</td>\n",
              "      <td>0.864029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HGB_deeper</td>\n",
              "      <td>28209.324614</td>\n",
              "      <td>7098.184741</td>\n",
              "      <td>0.131582</td>\n",
              "      <td>0.017709</td>\n",
              "      <td>0.862389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Stacking_Trees</td>\n",
              "      <td>32975.573150</td>\n",
              "      <td>9325.965034</td>\n",
              "      <td>0.136671</td>\n",
              "      <td>0.018095</td>\n",
              "      <td>0.812638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTrees_wide</td>\n",
              "      <td>29455.191587</td>\n",
              "      <td>7018.788362</td>\n",
              "      <td>0.138933</td>\n",
              "      <td>0.014702</td>\n",
              "      <td>0.851372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RF_regularized</td>\n",
              "      <td>28995.178491</td>\n",
              "      <td>6142.550461</td>\n",
              "      <td>0.139225</td>\n",
              "      <td>0.015636</td>\n",
              "      <td>0.858385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RF_unbounded</td>\n",
              "      <td>28999.952012</td>\n",
              "      <td>5101.197091</td>\n",
              "      <td>0.141332</td>\n",
              "      <td>0.013825</td>\n",
              "      <td>0.860771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>HGB_with_pca</td>\n",
              "      <td>30607.206639</td>\n",
              "      <td>4972.871890</td>\n",
              "      <td>0.143883</td>\n",
              "      <td>0.013130</td>\n",
              "      <td>0.845124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KernelRidge_rbf</td>\n",
              "      <td>33235.571341</td>\n",
              "      <td>4796.911428</td>\n",
              "      <td>0.342818</td>\n",
              "      <td>0.236861</td>\n",
              "      <td>0.820888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              model     rmse_mean     rmse_std  log_rmse_mean  log_rmse_std   r2_mean\n",
              "0       Bagging_HGB  27399.551344  6357.185771       0.125295      0.015580  0.872584\n",
              "1   Voting_TopTrees  26891.805115  7207.402720       0.125962      0.016404  0.873663\n",
              "2        GBR_depth3  26850.105434  7685.488876       0.127057      0.015513  0.872124\n",
              "3        GBR_depth4  26999.786581  6780.784243       0.128500      0.015043  0.873631\n",
              "4      HGB_baseline  28193.519974  6890.107412       0.131251      0.017017  0.863069\n",
              "5     LogTarget_HGB  27655.919103  5724.381698       0.131467      0.014711  0.871659\n",
              "6     HGB_shrinkage  28360.440354  6010.141091       0.131557      0.013790  0.864029\n",
              "7        HGB_deeper  28209.324614  7098.184741       0.131582      0.017709  0.862389\n",
              "8    Stacking_Trees  32975.573150  9325.965034       0.136671      0.018095  0.812638\n",
              "9   ExtraTrees_wide  29455.191587  7018.788362       0.138933      0.014702  0.851372\n",
              "10   RF_regularized  28995.178491  6142.550461       0.139225      0.015636  0.858385\n",
              "11     RF_unbounded  28999.952012  5101.197091       0.141332      0.013825  0.860771\n",
              "12     HGB_with_pca  30607.206639  4972.871890       0.143883      0.013130  0.845124\n",
              "13  KernelRidge_rbf  33235.571341  4796.911428       0.342818      0.236861  0.820888"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = evaluate_pipelines(model_registry, X_fe, y, cv)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>rmse_mean</th>\n",
              "      <th>rmse_std</th>\n",
              "      <th>log_rmse_mean</th>\n",
              "      <th>log_rmse_std</th>\n",
              "      <th>r2_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bagging_HGB</td>\n",
              "      <td>27399.551344</td>\n",
              "      <td>6357.185771</td>\n",
              "      <td>0.125295</td>\n",
              "      <td>0.015580</td>\n",
              "      <td>0.872584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Voting_TopTrees</td>\n",
              "      <td>26891.805115</td>\n",
              "      <td>7207.402720</td>\n",
              "      <td>0.125962</td>\n",
              "      <td>0.016404</td>\n",
              "      <td>0.873663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GBR_depth3</td>\n",
              "      <td>26850.105434</td>\n",
              "      <td>7685.488876</td>\n",
              "      <td>0.127057</td>\n",
              "      <td>0.015513</td>\n",
              "      <td>0.872124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GBR_depth4</td>\n",
              "      <td>26999.786581</td>\n",
              "      <td>6780.784243</td>\n",
              "      <td>0.128500</td>\n",
              "      <td>0.015043</td>\n",
              "      <td>0.873631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HGB_baseline</td>\n",
              "      <td>28193.519974</td>\n",
              "      <td>6890.107412</td>\n",
              "      <td>0.131251</td>\n",
              "      <td>0.017017</td>\n",
              "      <td>0.863069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LogTarget_HGB</td>\n",
              "      <td>27655.919103</td>\n",
              "      <td>5724.381698</td>\n",
              "      <td>0.131467</td>\n",
              "      <td>0.014711</td>\n",
              "      <td>0.871659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             model     rmse_mean     rmse_std  log_rmse_mean  log_rmse_std   r2_mean\n",
              "0      Bagging_HGB  27399.551344  6357.185771       0.125295      0.015580  0.872584\n",
              "1  Voting_TopTrees  26891.805115  7207.402720       0.125962      0.016404  0.873663\n",
              "2       GBR_depth3  26850.105434  7685.488876       0.127057      0.015513  0.872124\n",
              "3       GBR_depth4  26999.786581  6780.784243       0.128500      0.015043  0.873631\n",
              "4     HGB_baseline  28193.519974  6890.107412       0.131251      0.017017  0.863069\n",
              "5    LogTarget_HGB  27655.919103  5724.381698       0.131467      0.014711  0.871659"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_models = results_df.head(6)\n",
        "top_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Bagging_HGB', 'GBR_depth3')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_log_model = results_df.iloc[0][\"model\"]\n",
        "best_rmse_model = results_df.sort_values(\"rmse_mean\").iloc[0][\"model\"]\n",
        "\n",
        "best_log_model, best_rmse_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_save(model_name: str, pipeline: Pipeline) -> Path:\n",
        "    fitted = clone(pipeline)\n",
        "    fitted.fit(X_fe, y)\n",
        "    predictions = fitted.predict(test_fe)\n",
        "    submission = pd.DataFrame({\"Id\": test_fe.index, \"SalePrice\": predictions})\n",
        "    output_path = SUBMISSIONS_DIR / f\"{model_name}_submission.csv\"\n",
        "    submission.to_csv(output_path, index=False)\n",
        "    return output_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Bagging_HGB': PosixPath('../data/Bagging_HGB_submission.csv'),\n",
              " 'Voting_TopTrees': PosixPath('../data/Voting_TopTrees_submission.csv'),\n",
              " 'GBR_depth3': PosixPath('../data/GBR_depth3_submission.csv'),\n",
              " 'GBR_depth4': PosixPath('../data/GBR_depth4_submission.csv')}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission_candidates = results_df.head(4)[\"model\"].tolist()\n",
        "submission_paths = {name: train_and_save(name, model_registry[name]) for name in submission_candidates}\n",
        "submission_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def blend_and_save(blend_name: str, model_names: List[str], weights: Optional[List[float]] = None) -> Path:\n",
        "    if weights is not None and len(weights) != len(model_names):\n",
        "        raise ValueError(\"weights must match the number of models\")\n",
        "\n",
        "    preds = []\n",
        "    for name in model_names:\n",
        "        fitted = clone(model_registry[name])\n",
        "        fitted.fit(X_fe, y)\n",
        "        preds.append(fitted.predict(test_fe))\n",
        "\n",
        "    preds = np.vstack(preds)\n",
        "    if weights is None:\n",
        "        blended = preds.mean(axis=0)\n",
        "    else:\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        blended = np.average(preds, axis=0, weights=weights)\n",
        "\n",
        "    blend_path = SUBMISSIONS_DIR / f\"{blend_name}_submission.csv\"\n",
        "    pd.DataFrame({\"Id\": test_fe.index, \"SalePrice\": blended}).to_csv(blend_path, index=False)\n",
        "    return blend_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(PosixPath('../data/blend_top3_submission.csv'),\n",
              " PosixPath('../data/blend_weighted_submission.csv'))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top3_blend_path = blend_and_save(\"blend_top3\", submission_candidates[:3])\n",
        "weighted_blend_path = blend_and_save(\"blend_weighted\", submission_candidates, weights=[0.4, 0.3, 0.2, 0.1])\n",
        "top3_blend_path, weighted_blend_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !kaggle competitions submit \\\n",
        "#     -c house-prices-advanced-regression-techniques \\\n",
        "#     -f f\"../data/{best_log_model}_submission.csv\" \\\n",
        "#     -m f\"Final model - log metric ({best_log_model})\"\n",
        "\n",
        "# !kaggle competitions submit \\\n",
        "#     -c house-prices-advanced-regression-techniques \\\n",
        "#     -f f\"../data/{best_rmse_model}_submission.csv\" \\\n",
        "#     -m f\"Final model - rmse metric ({best_rmse_model})\"\n",
        "\n",
        "# for candidate in submission_candidates:\n",
        "#     print(candidate)\n",
        "    # !kaggle competitions submit \\\n",
        "    #     -c house-prices-advanced-regression-techniques \\\n",
        "    #     -f f\"../data/{candidate}_submission.csv\" \\\n",
        "    #     -m f\"Final model - single run ({candidate})\"\n",
        "\n",
        "# !kaggle competitions submit \\\n",
        "#     -c house-prices-advanced-regression-techniques \\\n",
        "#     -f \"../data/blend_top3_submission.csv\" \\\n",
        "#     -m \"Final model - blended top3\"\n",
        "\n",
        "# !kaggle competitions submit \\\n",
        "#     -c house-prices-advanced-regression-techniques \\\n",
        "#     -f \"../data/blend_weighted_submission.csv\" \\\n",
        "#     -m \"Final model - weighted blend\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../images/final.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1174 / 6075 = ~best 20%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../images/placement.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
