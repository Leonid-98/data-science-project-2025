{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r ../requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "with open(\"../.secrets/kaggle.json\") as f:\n",
        "    creds = json.load(f)\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
        "os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import clone\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "DATA_DIR = Path(\"../data\")\n",
        "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
        "TEST_PATH = DATA_DIR / \"test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36, 43)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "train_df = train_df.set_index(\"Id\")\n",
        "test_df = test_df.set_index(\"Id\")\n",
        "\n",
        "y = train_df[\"SalePrice\"]\n",
        "X = train_df.drop(columns=\"SalePrice\")\n",
        "\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "len(numeric_features), len(categorical_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- I split the columns into numeric vs. categorical so I can run different cleaners on them (numbers get scaled, categories get one-hot encoded).\n",
        "- This baseline only uses a single Ridge regressor, so all the heavy lifting happens in the preprocessing block below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rmse': np.float64(30642.20118234258),\n",
              " 'r2': 0.8775874105042153,\n",
              " 'naive_rmse': np.float64(87619.03450611533)}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Numbers get median-filled to keep outliers from shifting things, then I normalize variance so Ridge treats every scale fairly.\n",
        "numeric_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Categoricals just need the most frequent label + one-hot so the linear model can read them.\n",
        "categorical_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ColumnTransformer keeps both pipelines in sync and makes sure the column order is deterministic for Ridge.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipeline, numeric_features),\n",
        "        (\"cat\", categorical_pipeline, categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Ridge with alpha=10 is my \"starter\" model: it shrinks noisy coefficients without being too aggressive.\n",
        "baseline_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"regressor\", Ridge(alpha=10.0)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Hold out 20% so I can sanity-check scores before touching Kaggle.\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "baseline_pipeline.fit(X_train, y_train)\n",
        "\n",
        "valid_preds = baseline_pipeline.predict(X_valid)\n",
        "mse = mean_squared_error(y_valid, valid_preds)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_valid, valid_preds)\n",
        "\n",
        "# Compare against the dumb \"predict average price\" strategy to prove the pipeline actually helps.\n",
        "naive_pred = np.full_like(y_valid, y_train.mean(), dtype=float)\n",
        "naive_mse = mean_squared_error(y_valid, naive_pred)\n",
        "naive_rmse = np.sqrt(naive_mse)\n",
        "\n",
        "{\"rmse\": rmse, \"r2\": r2, \"naive_rmse\": naive_rmse}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kaggle log-RMSE validation\n",
        "Kaggle scores submissions using the RMSE between the logarithms of predicted and observed prices. This cell reports that metric for the validation split so we can anticipate leaderboard behaviour.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clamp predictions to >=1 so the log metric behaves (Kaggle also guards against negative sale prices).\n",
        "safe_valid_preds = np.clip(valid_preds, 1, None)\n",
        "safe_naive_preds = np.clip(naive_pred, 1, None)\n",
        "\n",
        "log_rmse = np.sqrt(mean_squared_error(np.log(y_valid), np.log(safe_valid_preds)))\n",
        "log_naive_rmse = np.sqrt(mean_squared_error(np.log(y_valid), np.log(safe_naive_preds)))\n",
        "\n",
        "{\"kaggle_log_rmse\": log_rmse, \"baseline_log_rmse\": log_naive_rmse}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(PosixPath('../data/baseline_submission.csv'),\n",
              "      Id      SalePrice\n",
              " 0  1461  103172.739208\n",
              " 1  1462  151293.867088\n",
              " 2  1463  173090.469195\n",
              " 3  1464  192257.716720\n",
              " 4  1465  202619.866494)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retrain on the full dataset before generating the CSV so Kaggle sees every observation I have.\n",
        "final_pipeline = clone(baseline_pipeline)\n",
        "final_pipeline.fit(X, y)\n",
        "\n",
        "# Nothing fancy here—just predict on the test set and store it for upload.\n",
        "test_predictions = final_pipeline.predict(test_df)\n",
        "submission_df = pd.DataFrame({\"Id\": test_df.index, \"SalePrice\": test_predictions})\n",
        "\n",
        "submission_path = DATA_DIR / \"baseline_submission.csv\"\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "\n",
        "submission_path, submission_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████| 33.7k/33.7k [00:00<00:00, 71.9kB/s]\n",
            "Successfully submitted to House Prices - Advanced Regression Techniques"
          ]
        }
      ],
      "source": [
        "# !kaggle competitions submit -c house-prices-advanced-regression-techniques -f ../data/baseline_submission.csv -m \"Baseline\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](../images/baseline.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
